{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "gpuType": "T4",
      "provenance": []
    },
    "accelerator": "GPU",
    "kaggle": {
      "accelerator": "gpu"
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -U transformers\n",
        "!pip install git+https://github.com/huggingface/parler-tts.git\n",
        "!pip install soundfile\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3192
        },
        "id": "m1_SlgFPsGQ4",
        "outputId": "a8516266-4dc4-4ddf-c510-502a8bff3db4"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.51.3)\n",
            "Collecting transformers\n",
            "  Using cached transformers-4.55.3-py3-none-any.whl.metadata (41 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.19.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.34.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.21.4)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2024.12.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.14.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.7)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.8.3)\n",
            "Using cached transformers-4.55.3-py3-none-any.whl (11.3 MB)\n",
            "Installing collected packages: transformers\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.51.3\n",
            "    Uninstalling transformers-4.51.3:\n",
            "      Successfully uninstalled transformers-4.51.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "parler-tts 0.2.2 requires transformers<=4.46.1,>=4.46.1, but you have transformers 4.55.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed transformers-4.55.3\n",
            "Collecting git+https://github.com/huggingface/parler-tts.git\n",
            "  Cloning https://github.com/huggingface/parler-tts.git to /tmp/pip-req-build-lpprdya4\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/parler-tts.git /tmp/pip-req-build-lpprdya4\n",
            "  Resolved https://github.com/huggingface/parler-tts.git to commit d108732cd57788ec86bc857d99a6cabd66663d68\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting transformers<=4.46.1,>=4.46.1 (from parler_tts==0.2.2)\n",
            "  Using cached transformers-4.46.1-py3-none-any.whl.metadata (44 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from parler_tts==0.2.2) (2.8.0+cu126)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.12/dist-packages (from parler_tts==0.2.2) (0.2.1)\n",
            "Requirement already satisfied: descript-audio-codec in /usr/local/lib/python3.12/dist-packages (from parler_tts==0.2.2) (1.0.0)\n",
            "Collecting descript-audiotools@ git+https://github.com/descriptinc/audiotools (from parler_tts==0.2.2)\n",
            "  Cloning https://github.com/descriptinc/audiotools to /tmp/pip-install-g6z7tp54/descript-audiotools_28717ddf6b974eb9b57e8e3d6f094883\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/descriptinc/audiotools /tmp/pip-install-g6z7tp54/descript-audiotools_28717ddf6b974eb9b57e8e3d6f094883\n",
            "  Resolved https://github.com/descriptinc/audiotools to commit 348ebf2034ce24e2a91a553e3171cb00c0c71678\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: protobuf>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from parler_tts==0.2.2) (5.29.5)\n",
            "Requirement already satisfied: argbind in /usr/local/lib/python3.12/dist-packages (from descript-audiotools@ git+https://github.com/descriptinc/audiotools->parler_tts==0.2.2) (0.3.9)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from descript-audiotools@ git+https://github.com/descriptinc/audiotools->parler_tts==0.2.2) (1.26.4)\n",
            "Requirement already satisfied: soundfile in /usr/local/lib/python3.12/dist-packages (from descript-audiotools@ git+https://github.com/descriptinc/audiotools->parler_tts==0.2.2) (0.13.1)\n",
            "Requirement already satisfied: pyloudnorm in /usr/local/lib/python3.12/dist-packages (from descript-audiotools@ git+https://github.com/descriptinc/audiotools->parler_tts==0.2.2) (0.1.1)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.12/dist-packages (from descript-audiotools@ git+https://github.com/descriptinc/audiotools->parler_tts==0.2.2) (6.5.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from descript-audiotools@ git+https://github.com/descriptinc/audiotools->parler_tts==0.2.2) (1.16.1)\n",
            "Requirement already satisfied: julius in /usr/local/lib/python3.12/dist-packages (from descript-audiotools@ git+https://github.com/descriptinc/audiotools->parler_tts==0.2.2) (0.2.7)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.12/dist-packages (from descript-audiotools@ git+https://github.com/descriptinc/audiotools->parler_tts==0.2.2) (2.8.0+cu126)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.12/dist-packages (from descript-audiotools@ git+https://github.com/descriptinc/audiotools->parler_tts==0.2.2) (0.6.1)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.12/dist-packages (from descript-audiotools@ git+https://github.com/descriptinc/audiotools->parler_tts==0.2.2) (7.34.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from descript-audiotools@ git+https://github.com/descriptinc/audiotools->parler_tts==0.2.2) (13.9.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from descript-audiotools@ git+https://github.com/descriptinc/audiotools->parler_tts==0.2.2) (3.10.0)\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.12/dist-packages (from descript-audiotools@ git+https://github.com/descriptinc/audiotools->parler_tts==0.2.2) (0.11.0)\n",
            "Requirement already satisfied: pystoi in /usr/local/lib/python3.12/dist-packages (from descript-audiotools@ git+https://github.com/descriptinc/audiotools->parler_tts==0.2.2) (0.4.1)\n",
            "Requirement already satisfied: torch_stoi in /usr/local/lib/python3.12/dist-packages (from descript-audiotools@ git+https://github.com/descriptinc/audiotools->parler_tts==0.2.2) (0.2.3)\n",
            "Requirement already satisfied: flatten-dict in /usr/local/lib/python3.12/dist-packages (from descript-audiotools@ git+https://github.com/descriptinc/audiotools->parler_tts==0.2.2) (0.4.2)\n",
            "Requirement already satisfied: markdown2 in /usr/local/lib/python3.12/dist-packages (from descript-audiotools@ git+https://github.com/descriptinc/audiotools->parler_tts==0.2.2) (2.5.4)\n",
            "Requirement already satisfied: randomname in /usr/local/lib/python3.12/dist-packages (from descript-audiotools@ git+https://github.com/descriptinc/audiotools->parler_tts==0.2.2) (0.2.1)\n",
            "Collecting protobuf>=4.0.0 (from parler_tts==0.2.2)\n",
            "  Using cached protobuf-4.25.8-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.12/dist-packages (from descript-audiotools@ git+https://github.com/descriptinc/audiotools->parler_tts==0.2.2) (2.19.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from descript-audiotools@ git+https://github.com/descriptinc/audiotools->parler_tts==0.2.2) (4.67.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers<=4.46.1,>=4.46.1->parler_tts==0.2.2) (3.19.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.12/dist-packages (from transformers<=4.46.1,>=4.46.1->parler_tts==0.2.2) (0.34.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers<=4.46.1,>=4.46.1->parler_tts==0.2.2) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers<=4.46.1,>=4.46.1->parler_tts==0.2.2) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers<=4.46.1,>=4.46.1->parler_tts==0.2.2) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers<=4.46.1,>=4.46.1->parler_tts==0.2.2) (2.32.4)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.12/dist-packages (from transformers<=4.46.1,>=4.46.1->parler_tts==0.2.2) (0.6.2)\n",
            "Collecting tokenizers<0.21,>=0.20 (from transformers<=4.46.1,>=4.46.1->parler_tts==0.2.2)\n",
            "  Using cached tokenizers-0.20.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers<=4.46.1,>=4.46.1->parler_tts==0.2.2) (2024.12.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers<=4.46.1,>=4.46.1->parler_tts==0.2.2) (4.14.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers<=4.46.1,>=4.46.1->parler_tts==0.2.2) (1.1.7)\n",
            "Requirement already satisfied: docstring-parser in /usr/local/lib/python3.12/dist-packages (from argbind->descript-audiotools@ git+https://github.com/descriptinc/audiotools->parler_tts==0.2.2) (0.17.0)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.12/dist-packages (from descript-audio-codec->parler_tts==0.2.2) (0.8.1)\n",
            "Requirement already satisfied: six<2.0,>=1.12 in /usr/local/lib/python3.12/dist-packages (from flatten-dict->descript-audiotools@ git+https://github.com/descriptinc/audiotools->parler_tts==0.2.2) (1.17.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.12/dist-packages (from ipython->descript-audiotools@ git+https://github.com/descriptinc/audiotools->parler_tts==0.2.2) (75.2.0)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.12/dist-packages (from ipython->descript-audiotools@ git+https://github.com/descriptinc/audiotools->parler_tts==0.2.2) (0.19.2)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.12/dist-packages (from ipython->descript-audiotools@ git+https://github.com/descriptinc/audiotools->parler_tts==0.2.2) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.12/dist-packages (from ipython->descript-audiotools@ git+https://github.com/descriptinc/audiotools->parler_tts==0.2.2) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.12/dist-packages (from ipython->descript-audiotools@ git+https://github.com/descriptinc/audiotools->parler_tts==0.2.2) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from ipython->descript-audiotools@ git+https://github.com/descriptinc/audiotools->parler_tts==0.2.2) (3.0.51)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.12/dist-packages (from ipython->descript-audiotools@ git+https://github.com/descriptinc/audiotools->parler_tts==0.2.2) (2.19.2)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.12/dist-packages (from ipython->descript-audiotools@ git+https://github.com/descriptinc/audiotools->parler_tts==0.2.2) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.12/dist-packages (from ipython->descript-audiotools@ git+https://github.com/descriptinc/audiotools->parler_tts==0.2.2) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.12/dist-packages (from ipython->descript-audiotools@ git+https://github.com/descriptinc/audiotools->parler_tts==0.2.2) (4.9.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.12/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->descript-audiotools@ git+https://github.com/descriptinc/audiotools->parler_tts==0.2.2) (0.2.13)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.12/dist-packages (from jedi>=0.16->ipython->descript-audiotools@ git+https://github.com/descriptinc/audiotools->parler_tts==0.2.2) (0.8.4)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.12/dist-packages (from pexpect>4.3->ipython->descript-audiotools@ git+https://github.com/descriptinc/audiotools->parler_tts==0.2.2) (0.7.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->parler_tts==0.2.2) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch->parler_tts==0.2.2) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->parler_tts==0.2.2) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->parler_tts==0.2.2) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->parler_tts==0.2.2) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch->parler_tts==0.2.2) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch->parler_tts==0.2.2) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch->parler_tts==0.2.2) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch->parler_tts==0.2.2) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch->parler_tts==0.2.2) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch->parler_tts==0.2.2) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch->parler_tts==0.2.2) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch->parler_tts==0.2.2) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch->parler_tts==0.2.2) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->parler_tts==0.2.2) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch->parler_tts==0.2.2) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch->parler_tts==0.2.2) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch->parler_tts==0.2.2) (3.4.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->parler_tts==0.2.2) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->parler_tts==0.2.2) (3.0.2)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.12/dist-packages (from librosa->descript-audiotools@ git+https://github.com/descriptinc/audiotools->parler_tts==0.2.2) (3.0.1)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.12/dist-packages (from librosa->descript-audiotools@ git+https://github.com/descriptinc/audiotools->parler_tts==0.2.2) (0.60.0)\n",
            "Requirement already satisfied: scikit-learn>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from librosa->descript-audiotools@ git+https://github.com/descriptinc/audiotools->parler_tts==0.2.2) (1.6.1)\n",
            "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.12/dist-packages (from librosa->descript-audiotools@ git+https://github.com/descriptinc/audiotools->parler_tts==0.2.2) (1.5.1)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.12/dist-packages (from librosa->descript-audiotools@ git+https://github.com/descriptinc/audiotools->parler_tts==0.2.2) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.12/dist-packages (from librosa->descript-audiotools@ git+https://github.com/descriptinc/audiotools->parler_tts==0.2.2) (0.5.0.post1)\n",
            "Requirement already satisfied: lazy_loader>=0.1 in /usr/local/lib/python3.12/dist-packages (from librosa->descript-audiotools@ git+https://github.com/descriptinc/audiotools->parler_tts==0.2.2) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.12/dist-packages (from librosa->descript-audiotools@ git+https://github.com/descriptinc/audiotools->parler_tts==0.2.2) (1.1.1)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.12/dist-packages (from numba>=0.51.0->librosa->descript-audiotools@ git+https://github.com/descriptinc/audiotools->parler_tts==0.2.2) (0.43.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from pooch>=1.1->librosa->descript-audiotools@ git+https://github.com/descriptinc/audiotools->parler_tts==0.2.2) (4.3.8)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers<=4.46.1,>=4.46.1->parler_tts==0.2.2) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers<=4.46.1,>=4.46.1->parler_tts==0.2.2) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers<=4.46.1,>=4.46.1->parler_tts==0.2.2) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers<=4.46.1,>=4.46.1->parler_tts==0.2.2) (2025.8.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.1.0->librosa->descript-audiotools@ git+https://github.com/descriptinc/audiotools->parler_tts==0.2.2) (3.6.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.12/dist-packages (from soundfile->descript-audiotools@ git+https://github.com/descriptinc/audiotools->parler_tts==0.2.2) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.0->soundfile->descript-audiotools@ git+https://github.com/descriptinc/audiotools->parler_tts==0.2.2) (2.22)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->descript-audiotools@ git+https://github.com/descriptinc/audiotools->parler_tts==0.2.2) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->descript-audiotools@ git+https://github.com/descriptinc/audiotools->parler_tts==0.2.2) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->descript-audiotools@ git+https://github.com/descriptinc/audiotools->parler_tts==0.2.2) (4.59.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->descript-audiotools@ git+https://github.com/descriptinc/audiotools->parler_tts==0.2.2) (1.4.9)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib->descript-audiotools@ git+https://github.com/descriptinc/audiotools->parler_tts==0.2.2) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->descript-audiotools@ git+https://github.com/descriptinc/audiotools->parler_tts==0.2.2) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib->descript-audiotools@ git+https://github.com/descriptinc/audiotools->parler_tts==0.2.2) (2.9.0.post0)\n",
            "Requirement already satisfied: future>=0.16.0 in /usr/local/lib/python3.12/dist-packages (from pyloudnorm->descript-audiotools@ git+https://github.com/descriptinc/audiotools->parler_tts==0.2.2) (1.0.0)\n",
            "Requirement already satisfied: fire in /usr/local/lib/python3.12/dist-packages (from randomname->descript-audiotools@ git+https://github.com/descriptinc/audiotools->parler_tts==0.2.2) (0.7.1)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.12/dist-packages (from fire->randomname->descript-audiotools@ git+https://github.com/descriptinc/audiotools->parler_tts==0.2.2) (3.1.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->descript-audiotools@ git+https://github.com/descriptinc/audiotools->parler_tts==0.2.2) (4.0.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->descript-audiotools@ git+https://github.com/descriptinc/audiotools->parler_tts==0.2.2) (0.1.2)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.12/dist-packages (from tensorboard->descript-audiotools@ git+https://github.com/descriptinc/audiotools->parler_tts==0.2.2) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.12/dist-packages (from tensorboard->descript-audiotools@ git+https://github.com/descriptinc/audiotools->parler_tts==0.2.2) (1.74.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard->descript-audiotools@ git+https://github.com/descriptinc/audiotools->parler_tts==0.2.2) (3.8.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard->descript-audiotools@ git+https://github.com/descriptinc/audiotools->parler_tts==0.2.2) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard->descript-audiotools@ git+https://github.com/descriptinc/audiotools->parler_tts==0.2.2) (3.1.3)\n",
            "Using cached protobuf-4.25.8-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
            "Using cached transformers-4.46.1-py3-none-any.whl (10.0 MB)\n",
            "Using cached tokenizers-0.20.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
            "Installing collected packages: protobuf, tokenizers, transformers\n",
            "\u001b[2K  Attempting uninstall: protobuf\n",
            "\u001b[2K    Found existing installation: protobuf 5.29.5\n",
            "\u001b[2K    Uninstalling protobuf-5.29.5:\n",
            "\u001b[2K      Successfully uninstalled protobuf-5.29.5\n",
            "\u001b[2K  Attempting uninstall: tokenizers\n",
            "\u001b[2K    Found existing installation: tokenizers 0.21.4\n",
            "\u001b[2K    Uninstalling tokenizers-0.21.4:\n",
            "\u001b[2K      Successfully uninstalled tokenizers-0.21.4\n",
            "\u001b[2K  Attempting uninstall: transformers\n",
            "\u001b[2K    Found existing installation: transformers 4.55.3\n",
            "\u001b[2K    Uninstalling transformers-4.55.3:\n",
            "\u001b[2K      Successfully uninstalled transformers-4.55.3\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3/3\u001b[0m [transformers]\n",
            "\u001b[1A\u001b[2K\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ydf 0.13.0 requires protobuf<7.0.0,>=5.29.1, but you have protobuf 4.25.8 which is incompatible.\n",
            "grpcio-status 1.71.2 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 4.25.8 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed protobuf-4.25.8 tokenizers-0.20.3 transformers-4.46.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              },
              "id": "1792d25110be47c8b5eb4a661ac0ff7b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: soundfile in /usr/local/lib/python3.12/dist-packages (0.13.1)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.12/dist-packages (from soundfile) (1.17.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from soundfile) (1.26.4)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.0->soundfile) (2.22)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from parler_tts import ParlerTTSForConditionalGeneration\n",
        "from transformers import AutoTokenizer\n",
        "import soundfile as sf\n",
        "import os\n",
        "\n",
        "# Set your Hugging Face access token\n",
        "os.environ[\"HF_TOKEN\"] = \"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\"\n",
        "\n",
        "# Choose your device (GPU or CPU)\n",
        "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# Load the model and tokenizers with access token\n",
        "model = ParlerTTSForConditionalGeneration.from_pretrained(\n",
        "    \"HelpingAI/HelpingAI-TTS-v1\",\n",
        "    token=\"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\"\n",
        ").to(device)\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\n",
        "    \"HelpingAI/HelpingAI-TTS-v1\",\n",
        "    token=\"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\"\n",
        ")\n",
        "\n",
        "description_tokenizer = AutoTokenizer.from_pretrained(\n",
        "    model.config.text_encoder._name_or_path,\n",
        "    token=\"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\"\n",
        ")\n",
        "\n",
        "# Customize your inputs: text + description\n",
        "prompt = \"Hey, what's up? How's it going?\"\n",
        "description = \"A friendly, upbeat, and casual tone with a moderate speed. Speaker sounds confident and relaxed.\"\n",
        "\n",
        "# Tokenize the inputs\n",
        "input_ids = description_tokenizer(description, return_tensors=\"pt\").input_ids.to(device)\n",
        "prompt_input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids.to(device)\n",
        "\n",
        "# Generate the audio\n",
        "generation = model.generate(input_ids=input_ids, prompt_input_ids=prompt_input_ids)\n",
        "audio_arr = generation.cpu().numpy().squeeze()\n",
        "\n",
        "# Save the audio to a file\n",
        "sf.write(\"output.wav\", audio_arr, model.config.sampling_rate)\n",
        "\n",
        "print(f\"Audio generated and saved as 'output.wav' with sampling rate: {model.config.sampling_rate}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "-gjH2ppAsKrn",
        "outputId": "a0346ab8-73b0-43cf-d5da-c015ab22c7bb"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:parler_tts.modeling_parler_tts:Flash attention 2 is not installed\n",
            "WARNING:parler_tts.modeling_parler_tts:Config of the text_encoder: <class 'transformers.models.t5.modeling_t5.T5EncoderModel'> is overwritten by shared text_encoder config: T5Config {\n",
            "  \"_name_or_path\": \"google/flan-t5-large\",\n",
            "  \"architectures\": [\n",
            "    \"T5ForConditionalGeneration\"\n",
            "  ],\n",
            "  \"classifier_dropout\": 0.0,\n",
            "  \"d_ff\": 2816,\n",
            "  \"d_kv\": 64,\n",
            "  \"d_model\": 1024,\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"dense_act_fn\": \"gelu_new\",\n",
            "  \"dropout_rate\": 0.1,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"feed_forward_proj\": \"gated-gelu\",\n",
            "  \"initializer_factor\": 1.0,\n",
            "  \"is_encoder_decoder\": true,\n",
            "  \"is_gated_act\": true,\n",
            "  \"layer_norm_epsilon\": 1e-06,\n",
            "  \"model_type\": \"t5\",\n",
            "  \"n_positions\": 512,\n",
            "  \"num_decoder_layers\": 24,\n",
            "  \"num_heads\": 16,\n",
            "  \"num_layers\": 24,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"relative_attention_max_distance\": 128,\n",
            "  \"relative_attention_num_buckets\": 32,\n",
            "  \"tie_word_embeddings\": false,\n",
            "  \"transformers_version\": \"4.46.1\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 32128\n",
            "}\n",
            "\n",
            "WARNING:parler_tts.modeling_parler_tts:Config of the audio_encoder: <class 'transformers.models.dac.modeling_dac.DacModel'> is overwritten by shared audio_encoder config: DacConfig {\n",
            "  \"_name_or_path\": \"ylacombe/dac_44khz\",\n",
            "  \"architectures\": [\n",
            "    \"DacModel\"\n",
            "  ],\n",
            "  \"codebook_dim\": 8,\n",
            "  \"codebook_loss_weight\": 1.0,\n",
            "  \"codebook_size\": 1024,\n",
            "  \"commitment_loss_weight\": 0.25,\n",
            "  \"decoder_hidden_size\": 1536,\n",
            "  \"downsampling_ratios\": [\n",
            "    2,\n",
            "    4,\n",
            "    8,\n",
            "    8\n",
            "  ],\n",
            "  \"encoder_hidden_size\": 64,\n",
            "  \"hidden_size\": 1024,\n",
            "  \"hop_length\": 512,\n",
            "  \"model_type\": \"dac\",\n",
            "  \"n_codebooks\": 9,\n",
            "  \"quantizer_dropout\": 0.0,\n",
            "  \"sampling_rate\": 44100,\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.46.1\",\n",
            "  \"upsampling_ratios\": [\n",
            "    8,\n",
            "    8,\n",
            "    4,\n",
            "    2\n",
            "  ]\n",
            "}\n",
            "\n",
            "WARNING:parler_tts.modeling_parler_tts:Config of the decoder: <class 'parler_tts.modeling_parler_tts.ParlerTTSForCausalLM'> is overwritten by shared decoder config: ParlerTTSDecoderConfig {\n",
            "  \"_name_or_path\": \"/fsx/yoach/tmp/artefacts/parler-tts-mini-v2-empty/decoder\",\n",
            "  \"activation_dropout\": 0.0,\n",
            "  \"activation_function\": \"gelu\",\n",
            "  \"add_cross_attention\": true,\n",
            "  \"architectures\": [\n",
            "    \"ParlerTTSForCausalLM\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bos_token_id\": 1025,\n",
            "  \"codebook_weights\": null,\n",
            "  \"cross_attention_implementation_strategy\": null,\n",
            "  \"delay_strategy\": \"delay\",\n",
            "  \"dropout\": 0.1,\n",
            "  \"eos_token_id\": 1024,\n",
            "  \"ffn_dim\": 4096,\n",
            "  \"hidden_size\": 1024,\n",
            "  \"initializer_factor\": 0.02,\n",
            "  \"is_decoder\": true,\n",
            "  \"layerdrop\": 0.0,\n",
            "  \"max_position_embeddings\": 4096,\n",
            "  \"model_type\": \"parler_tts_decoder\",\n",
            "  \"num_attention_heads\": 16,\n",
            "  \"num_codebooks\": 9,\n",
            "  \"num_cross_attention_key_value_heads\": 16,\n",
            "  \"num_hidden_layers\": 24,\n",
            "  \"num_key_value_heads\": 16,\n",
            "  \"pad_token_id\": 1024,\n",
            "  \"rope_embeddings\": false,\n",
            "  \"rope_theta\": 10000.0,\n",
            "  \"scale_embedding\": false,\n",
            "  \"tie_word_embeddings\": false,\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.46.1\",\n",
            "  \"use_cache\": true,\n",
            "  \"use_fused_lm_heads\": true,\n",
            "  \"vocab_size\": 1088\n",
            "}\n",
            "\n",
            "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Audio generated and saved as 'output.wav' with sampling rate: 44100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from transformers import pipeline\n",
        "\n",
        "# Set your Hugging Face access token\n",
        "os.environ[\"HF_TOKEN\"] = \"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\"\n",
        "\n",
        "# Create pipeline with access token\n",
        "pipe = pipeline(\n",
        "    \"text-to-speech\",\n",
        "    model=\"HelpingAI/HelpingAI-TTS-v1\",\n",
        "    token=\"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\"\n",
        ")\n",
        "\n",
        "# Generate speech\n",
        "text = \"Hello, this is a test of the HelpingAI TTS model!\"\n",
        "result = pipe(text)\n",
        "\n",
        "# Access the audio and sampling rate\n",
        "audio = result[\"audio\"]\n",
        "sampling_rate = result[\"sampling_rate\"]\n",
        "\n",
        "print(f\"Audio generated with sampling rate: {sampling_rate}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        },
        "id": "0JhMS3zwsQp7",
        "outputId": "a0f6b5f3-faf8-4238-d057-c5215e36c96b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "The checkpoint you are trying to load has model type `parler_tts` but Transformers does not recognize this architecture. This could be because of an issue with the checkpoint, or because your version of Transformers is out of date.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/auto/configuration_auto.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m   1033\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1034\u001b[0;31m                 \u001b[0mconfig_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCONFIG_MAPPING\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mconfig_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"model_type\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1035\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/auto/configuration_auto.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    735\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mapping\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 736\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    737\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'parler_tts'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2711430672.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Create pipeline with access token\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m pipe = pipeline(\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;34m\"text-to-speech\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"HelpingAI/HelpingAI-TTS-v1\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/pipelines/__init__.py\u001b[0m in \u001b[0;36mpipeline\u001b[0;34m(task, model, config, tokenizer, feature_extractor, image_processor, processor, framework, revision, use_fast, token, device, device_map, torch_dtype, trust_remote_code, model_kwargs, pipeline_class, **kwargs)\u001b[0m\n\u001b[1;32m    833\u001b[0m                     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"base_model_name_or_path\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 835\u001b[0;31m         config = AutoConfig.from_pretrained(\n\u001b[0m\u001b[1;32m    836\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_from_pipeline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode_revision\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcode_revision\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mhub_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    837\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/auto/configuration_auto.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m   1034\u001b[0m                 \u001b[0mconfig_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCONFIG_MAPPING\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mconfig_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"model_type\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1035\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1036\u001b[0;31m                 raise ValueError(\n\u001b[0m\u001b[1;32m   1037\u001b[0m                     \u001b[0;34mf\"The checkpoint you are trying to load has model type `{config_dict['model_type']}` \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                     \u001b[0;34m\"but Transformers does not recognize this architecture. This could be because of an \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: The checkpoint you are trying to load has model type `parler_tts` but Transformers does not recognize this architecture. This could be because of an issue with the checkpoint, or because your version of Transformers is out of date."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from parler_tts import ParlerTTSForConditionalGeneration\n",
        "from transformers import AutoTokenizer\n",
        "import soundfile as sf\n",
        "import os\n",
        "\n",
        "# Set your Hugging Face access token\n",
        "os.environ[\"HF_TOKEN\"] = \"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\"\n",
        "\n",
        "# Choose your device (GPU or CPU)\n",
        "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# Load the model and tokenizers with access token\n",
        "model = ParlerTTSForConditionalGeneration.from_pretrained(\n",
        "    \"HelpingAI/HelpingAI-TTS-v1\",\n",
        "    token=\"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\"\n",
        ").to(device)\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\n",
        "    \"HelpingAI/HelpingAI-TTS-v1\",\n",
        "    token=\"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\"\n",
        ")\n",
        "\n",
        "description_tokenizer = AutoTokenizer.from_pretrained(\n",
        "    model.config.text_encoder._name_or_path,\n",
        "    token=\"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\"\n",
        ")\n",
        "\n",
        "# Marathi sentence example\n",
        "prompt_marathi = \"नमस्कार! आज दिवस खूप सुंदर आहे. तुमचे कसे चालले आहे?\"\n",
        "\n",
        "# Description for Marathi voice\n",
        "description_marathi = \"A clear, warm Marathi voice with natural pronunciation and moderate speaking speed\"\n",
        "\n",
        "# Tokenize the inputs\n",
        "input_ids = description_tokenizer(description_marathi, return_tensors=\"pt\").input_ids.to(device)\n",
        "prompt_input_ids = tokenizer(prompt_marathi, return_tensors=\"pt\").input_ids.to(device)\n",
        "\n",
        "# Generate the audio\n",
        "generation = model.generate(input_ids=input_ids, prompt_input_ids=prompt_input_ids)\n",
        "audio_arr = generation.cpu().numpy().squeeze()\n",
        "\n",
        "# Save the audio to a file\n",
        "sf.write(\"marathi_speech.wav\", audio_arr, model.config.sampling_rate)\n",
        "\n",
        "print(\"Marathi speech generated and saved as 'marathi_speech.wav'!\")\n",
        "print(f\"Text spoken: {prompt_marathi}\")\n",
        "print(\"Translation: Hello! Today is a very beautiful day. How are things going for you?\")\n"
      ],
      "metadata": {
        "id": "4GV4w7MosqHG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from parler_tts import ParlerTTSForConditionalGeneration\n",
        "from transformers import AutoTokenizer\n",
        "import soundfile as sf\n",
        "import os\n",
        "\n",
        "# Set your Hugging Face access token\n",
        "os.environ[\"HF_TOKEN\"] = \"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\"\n",
        "\n",
        "# Choose your device (GPU or CPU)\n",
        "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# Load the model and tokenizers with access token\n",
        "model = ParlerTTSForConditionalGeneration.from_pretrained(\n",
        "    \"HelpingAI/HelpingAI-TTS-v1\",\n",
        "    token=\"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\"\n",
        ").to(device)\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\n",
        "    \"HelpingAI/HelpingAI-TTS-v1\",\n",
        "    token=\"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\"\n",
        ")\n",
        "\n",
        "description_tokenizer = AutoTokenizer.from_pretrained(\n",
        "    model.config.text_encoder._name_or_path,\n",
        "    token=\"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\"\n",
        ")\n",
        "\n",
        "# Marathi sentence\n",
        "prompt_marathi = \"नमस्कार! आज दिवस खूप सुंदर आहे. तुमचे कसे चालले आहे?\"\n",
        "\n",
        "# Description specifically for FEMALE voice\n",
        "description_marathi_female = \"A very young female speaker with a sweet, warm , soothing Marathi voice. She speaks clearly with natural pronunciation and a friendly, cheerful tone at moderate speed.\"\n",
        "\n",
        "# Tokenize the inputs\n",
        "input_ids = description_tokenizer(description_marathi_female, return_tensors=\"pt\").input_ids.to(device)\n",
        "prompt_input_ids = tokenizer(prompt_marathi, return_tensors=\"pt\").input_ids.to(device)\n",
        "\n",
        "# Generate the audio\n",
        "generation = model.generate(input_ids=input_ids, prompt_input_ids=prompt_input_ids)\n",
        "audio_arr = generation.cpu().numpy().squeeze()\n",
        "\n",
        "# Save the audio to a file\n",
        "sf.write(\"marathi_female_voice.wav\", audio_arr, model.config.sampling_rate)\n",
        "\n",
        "print(\"Marathi speech with female voice generated and saved as 'marathi_female_voice.wav'!\")\n",
        "print(f\"Text spoken: {prompt_marathi}\")\n",
        "print(\"Translation: Hello! Today is a very beautiful day. How are things going for you?\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "kSKkNPdgvPrY",
        "outputId": "84191dea-da8e-43ec-aa97-d421c9cc9d24"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:parler_tts.modeling_parler_tts:Config of the text_encoder: <class 'transformers.models.t5.modeling_t5.T5EncoderModel'> is overwritten by shared text_encoder config: T5Config {\n",
            "  \"_name_or_path\": \"google/flan-t5-large\",\n",
            "  \"architectures\": [\n",
            "    \"T5ForConditionalGeneration\"\n",
            "  ],\n",
            "  \"classifier_dropout\": 0.0,\n",
            "  \"d_ff\": 2816,\n",
            "  \"d_kv\": 64,\n",
            "  \"d_model\": 1024,\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"dense_act_fn\": \"gelu_new\",\n",
            "  \"dropout_rate\": 0.1,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"feed_forward_proj\": \"gated-gelu\",\n",
            "  \"initializer_factor\": 1.0,\n",
            "  \"is_encoder_decoder\": true,\n",
            "  \"is_gated_act\": true,\n",
            "  \"layer_norm_epsilon\": 1e-06,\n",
            "  \"model_type\": \"t5\",\n",
            "  \"n_positions\": 512,\n",
            "  \"num_decoder_layers\": 24,\n",
            "  \"num_heads\": 16,\n",
            "  \"num_layers\": 24,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"relative_attention_max_distance\": 128,\n",
            "  \"relative_attention_num_buckets\": 32,\n",
            "  \"tie_word_embeddings\": false,\n",
            "  \"transformers_version\": \"4.46.1\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 32128\n",
            "}\n",
            "\n",
            "WARNING:parler_tts.modeling_parler_tts:Config of the audio_encoder: <class 'transformers.models.dac.modeling_dac.DacModel'> is overwritten by shared audio_encoder config: DacConfig {\n",
            "  \"_name_or_path\": \"ylacombe/dac_44khz\",\n",
            "  \"architectures\": [\n",
            "    \"DacModel\"\n",
            "  ],\n",
            "  \"codebook_dim\": 8,\n",
            "  \"codebook_loss_weight\": 1.0,\n",
            "  \"codebook_size\": 1024,\n",
            "  \"commitment_loss_weight\": 0.25,\n",
            "  \"decoder_hidden_size\": 1536,\n",
            "  \"downsampling_ratios\": [\n",
            "    2,\n",
            "    4,\n",
            "    8,\n",
            "    8\n",
            "  ],\n",
            "  \"encoder_hidden_size\": 64,\n",
            "  \"hidden_size\": 1024,\n",
            "  \"hop_length\": 512,\n",
            "  \"model_type\": \"dac\",\n",
            "  \"n_codebooks\": 9,\n",
            "  \"quantizer_dropout\": 0.0,\n",
            "  \"sampling_rate\": 44100,\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.46.1\",\n",
            "  \"upsampling_ratios\": [\n",
            "    8,\n",
            "    8,\n",
            "    4,\n",
            "    2\n",
            "  ]\n",
            "}\n",
            "\n",
            "WARNING:parler_tts.modeling_parler_tts:Config of the decoder: <class 'parler_tts.modeling_parler_tts.ParlerTTSForCausalLM'> is overwritten by shared decoder config: ParlerTTSDecoderConfig {\n",
            "  \"_name_or_path\": \"/fsx/yoach/tmp/artefacts/parler-tts-mini-v2-empty/decoder\",\n",
            "  \"activation_dropout\": 0.0,\n",
            "  \"activation_function\": \"gelu\",\n",
            "  \"add_cross_attention\": true,\n",
            "  \"architectures\": [\n",
            "    \"ParlerTTSForCausalLM\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bos_token_id\": 1025,\n",
            "  \"codebook_weights\": null,\n",
            "  \"cross_attention_implementation_strategy\": null,\n",
            "  \"delay_strategy\": \"delay\",\n",
            "  \"dropout\": 0.1,\n",
            "  \"eos_token_id\": 1024,\n",
            "  \"ffn_dim\": 4096,\n",
            "  \"hidden_size\": 1024,\n",
            "  \"initializer_factor\": 0.02,\n",
            "  \"is_decoder\": true,\n",
            "  \"layerdrop\": 0.0,\n",
            "  \"max_position_embeddings\": 4096,\n",
            "  \"model_type\": \"parler_tts_decoder\",\n",
            "  \"num_attention_heads\": 16,\n",
            "  \"num_codebooks\": 9,\n",
            "  \"num_cross_attention_key_value_heads\": 16,\n",
            "  \"num_hidden_layers\": 24,\n",
            "  \"num_key_value_heads\": 16,\n",
            "  \"pad_token_id\": 1024,\n",
            "  \"rope_embeddings\": false,\n",
            "  \"rope_theta\": 10000.0,\n",
            "  \"scale_embedding\": false,\n",
            "  \"tie_word_embeddings\": false,\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.46.1\",\n",
            "  \"use_cache\": true,\n",
            "  \"use_fused_lm_heads\": true,\n",
            "  \"vocab_size\": 1088\n",
            "}\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Marathi speech with female voice generated and saved as 'marathi_female_voice.wav'!\n",
            "Text spoken: नमस्कार! आज दिवस खूप सुंदर आहे. तुमचे कसे चालले आहे?\n",
            "Translation: Hello! Today is a very beautiful day. How are things going for you?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from parler_tts import ParlerTTSForConditionalGeneration\n",
        "from transformers import AutoTokenizer\n",
        "import soundfile as sf\n",
        "import os\n",
        "\n",
        "# Set your Hugging Face access token\n",
        "os.environ[\"HF_TOKEN\"] = \"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\"\n",
        "\n",
        "# Choose your device (GPU or CPU)\n",
        "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# Load the model and tokenizers with access token\n",
        "model = ParlerTTSForConditionalGeneration.from_pretrained(\n",
        "    \"HelpingAI/HelpingAI-TTS-v1\",\n",
        "    token=\"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\"\n",
        ").to(device)\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\n",
        "    \"HelpingAI/HelpingAI-TTS-v1\",\n",
        "    token=\"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\"\n",
        ")\n",
        "\n",
        "description_tokenizer = AutoTokenizer.from_pretrained(\n",
        "    model.config.text_encoder._name_or_path,\n",
        "    token=\"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\"\n",
        ")\n",
        "\n",
        "# Hindi sentence\n",
        "prompt_hindi = \"एक समय की बात है, तीन भालू थे जो एक जंगल में अपने घर में साथ रहते थे। उनमें से एक छोटा सा भालू था, एक मध्यम आकार का भालू था और दूसरा एक बड़ा भालू था। उनमें से प्रत्येक के पास दलिया के लिए एक कटोरा था; छोटे छोटे भालू के लिए एक छोटा कटोरा; और मध्यम आकार के भालू के लिए एक मध्यम आकार का कटोरा; और बड़े बड़े भालू के लिए एक बड़ा कटोरा। और उनमें से प्रत्येक के पास बैठने के लिए एक कुर्सी थी; छोटे छोटे भालू के लिए एक छोटी कुर्सी; और मध्यम आकार के भालू के लिए एक मध्यम आकार की कुर्सी; और बड़े बड़े भालू के लिए एक बड़ी कुर्सी। और उनमें से प्रत्येक के पास सोने के लिए एक बिस्तर था; छोटे छोटे भालू के लिए एक छोटा बिस्तर; और मध्यम आकार के भालू के लिए एक मध्यम आकार का बिस्तर; और बड़े बड़े भालू के लिए एक बड़ा बिस्तर।\"\n",
        "\n",
        "# Description specifically for FEMALE voice in Hindi\n",
        "description_hindi_female = \"A very young female speaker with a sweet, warm, soothing Hindi voice. She speaks clearly with natural pronunciation and a friendly, cheerful tone at moderate speed.\"\n",
        "\n",
        "# Tokenize the inputs\n",
        "input_ids = description_tokenizer(description_hindi_female, return_tensors=\"pt\").input_ids.to(device)\n",
        "prompt_input_ids = tokenizer(prompt_hindi, return_tensors=\"pt\").input_ids.to(device)\n",
        "\n",
        "# Generate the audio\n",
        "generation = model.generate(input_ids=input_ids, prompt_input_ids=prompt_input_ids)\n",
        "audio_arr = generation.cpu().numpy().squeeze()\n",
        "\n",
        "# Save the audio to a file\n",
        "sf.write(\"hindi_female_voice.wav\", audio_arr, model.config.sampling_rate)\n",
        "\n",
        "print(\"Hindi speech with female voice generated and saved as 'hindi_female_voice.wav'!\")\n",
        "print(f\"Text spoken: {prompt_hindi}\")\n",
        "print(\"Translation: Hello! Today's day is very beautiful. How is your day going?\")\n"
      ],
      "metadata": {
        "id": "8C404hk9FDYh",
        "outputId": "da5b2b70-eb0e-4627-d28d-f6af9e604578",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:parler_tts.modeling_parler_tts:Config of the text_encoder: <class 'transformers.models.t5.modeling_t5.T5EncoderModel'> is overwritten by shared text_encoder config: T5Config {\n",
            "  \"_name_or_path\": \"google/flan-t5-large\",\n",
            "  \"architectures\": [\n",
            "    \"T5ForConditionalGeneration\"\n",
            "  ],\n",
            "  \"classifier_dropout\": 0.0,\n",
            "  \"d_ff\": 2816,\n",
            "  \"d_kv\": 64,\n",
            "  \"d_model\": 1024,\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"dense_act_fn\": \"gelu_new\",\n",
            "  \"dropout_rate\": 0.1,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"feed_forward_proj\": \"gated-gelu\",\n",
            "  \"initializer_factor\": 1.0,\n",
            "  \"is_encoder_decoder\": true,\n",
            "  \"is_gated_act\": true,\n",
            "  \"layer_norm_epsilon\": 1e-06,\n",
            "  \"model_type\": \"t5\",\n",
            "  \"n_positions\": 512,\n",
            "  \"num_decoder_layers\": 24,\n",
            "  \"num_heads\": 16,\n",
            "  \"num_layers\": 24,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"relative_attention_max_distance\": 128,\n",
            "  \"relative_attention_num_buckets\": 32,\n",
            "  \"tie_word_embeddings\": false,\n",
            "  \"transformers_version\": \"4.46.1\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 32128\n",
            "}\n",
            "\n",
            "WARNING:parler_tts.modeling_parler_tts:Config of the audio_encoder: <class 'transformers.models.dac.modeling_dac.DacModel'> is overwritten by shared audio_encoder config: DacConfig {\n",
            "  \"_name_or_path\": \"ylacombe/dac_44khz\",\n",
            "  \"architectures\": [\n",
            "    \"DacModel\"\n",
            "  ],\n",
            "  \"codebook_dim\": 8,\n",
            "  \"codebook_loss_weight\": 1.0,\n",
            "  \"codebook_size\": 1024,\n",
            "  \"commitment_loss_weight\": 0.25,\n",
            "  \"decoder_hidden_size\": 1536,\n",
            "  \"downsampling_ratios\": [\n",
            "    2,\n",
            "    4,\n",
            "    8,\n",
            "    8\n",
            "  ],\n",
            "  \"encoder_hidden_size\": 64,\n",
            "  \"hidden_size\": 1024,\n",
            "  \"hop_length\": 512,\n",
            "  \"model_type\": \"dac\",\n",
            "  \"n_codebooks\": 9,\n",
            "  \"quantizer_dropout\": 0.0,\n",
            "  \"sampling_rate\": 44100,\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.46.1\",\n",
            "  \"upsampling_ratios\": [\n",
            "    8,\n",
            "    8,\n",
            "    4,\n",
            "    2\n",
            "  ]\n",
            "}\n",
            "\n",
            "WARNING:parler_tts.modeling_parler_tts:Config of the decoder: <class 'parler_tts.modeling_parler_tts.ParlerTTSForCausalLM'> is overwritten by shared decoder config: ParlerTTSDecoderConfig {\n",
            "  \"_name_or_path\": \"/fsx/yoach/tmp/artefacts/parler-tts-mini-v2-empty/decoder\",\n",
            "  \"activation_dropout\": 0.0,\n",
            "  \"activation_function\": \"gelu\",\n",
            "  \"add_cross_attention\": true,\n",
            "  \"architectures\": [\n",
            "    \"ParlerTTSForCausalLM\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bos_token_id\": 1025,\n",
            "  \"codebook_weights\": null,\n",
            "  \"cross_attention_implementation_strategy\": null,\n",
            "  \"delay_strategy\": \"delay\",\n",
            "  \"dropout\": 0.1,\n",
            "  \"eos_token_id\": 1024,\n",
            "  \"ffn_dim\": 4096,\n",
            "  \"hidden_size\": 1024,\n",
            "  \"initializer_factor\": 0.02,\n",
            "  \"is_decoder\": true,\n",
            "  \"layerdrop\": 0.0,\n",
            "  \"max_position_embeddings\": 4096,\n",
            "  \"model_type\": \"parler_tts_decoder\",\n",
            "  \"num_attention_heads\": 16,\n",
            "  \"num_codebooks\": 9,\n",
            "  \"num_cross_attention_key_value_heads\": 16,\n",
            "  \"num_hidden_layers\": 24,\n",
            "  \"num_key_value_heads\": 16,\n",
            "  \"pad_token_id\": 1024,\n",
            "  \"rope_embeddings\": false,\n",
            "  \"rope_theta\": 10000.0,\n",
            "  \"scale_embedding\": false,\n",
            "  \"tie_word_embeddings\": false,\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.46.1\",\n",
            "  \"use_cache\": true,\n",
            "  \"use_fused_lm_heads\": true,\n",
            "  \"vocab_size\": 1088\n",
            "}\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hindi speech with female voice generated and saved as 'hindi_female_voice.wav'!\n",
            "Text spoken: एक समय की बात है, तीन भालू थे जो एक जंगल में अपने घर में साथ रहते थे। उनमें से एक छोटा सा भालू था, एक मध्यम आकार का भालू था और दूसरा एक बड़ा भालू था। उनमें से प्रत्येक के पास दलिया के लिए एक कटोरा था; छोटे छोटे भालू के लिए एक छोटा कटोरा; और मध्यम आकार के भालू के लिए एक मध्यम आकार का कटोरा; और बड़े बड़े भालू के लिए एक बड़ा कटोरा। और उनमें से प्रत्येक के पास बैठने के लिए एक कुर्सी थी; छोटे छोटे भालू के लिए एक छोटी कुर्सी; और मध्यम आकार के भालू के लिए एक मध्यम आकार की कुर्सी; और बड़े बड़े भालू के लिए एक बड़ी कुर्सी। और उनमें से प्रत्येक के पास सोने के लिए एक बिस्तर था; छोटे छोटे भालू के लिए एक छोटा बिस्तर; और मध्यम आकार के भालू के लिए एक मध्यम आकार का बिस्तर; और बड़े बड़े भालू के लिए एक बड़ा बिस्तर।\n",
            "Translation: Hello! Today's day is very beautiful. How is your day going?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "np6OQqG4yvCa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "R97WYE470ObN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ms1k4NBKy-qB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GZyJ50AZ5ocI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Uly6E5REy_rw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}